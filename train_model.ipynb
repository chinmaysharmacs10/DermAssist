{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61acfd9f-7835-4a98-ad67-90a94a0034c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import ast\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, WeightedRandomSampler\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, accuracy_score, hamming_loss\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, OneHotEncoder, LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(42)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07259ec3-13be-4a92-8087-b350233f98ae",
   "metadata": {},
   "source": [
    "## Create a Pytorch Dataset Class for the SCIN Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f32983-8ee7-4557-85d5-37fea7ade266",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCINDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.cases_csv = 'dataset/scin_cases.csv'\n",
    "        self.labels_csv = 'dataset/scin_labels.csv'\n",
    "        self.image_path_columns = ['image_1_path', 'image_2_path', 'image_3_path']\n",
    "        self.weighted_skin_condition_label = \"weighted_skin_condition_label\"\n",
    "        self.skin_condition_label = \"dermatologist_skin_condition_on_label_name\"\n",
    "\n",
    "        # Read SCIN metadata\n",
    "        cases_df = pd.read_csv(self.cases_csv, dtype={'case_id': str})\n",
    "        cases_df['case_id'] = cases_df['case_id'].astype(str)\n",
    "        labels_df = pd.read_csv(self.labels_csv, dtype={'case_id': str})\n",
    "        labels_df['case_id'] = labels_df['case_id'].astype(str)\n",
    "\n",
    "        # Merge different SCIN Metadata files on CASE ID\n",
    "        cases_df = pd.merge(cases_df, labels_df, on='case_id')\n",
    "\n",
    "        # Cleaning and Preprocessing\n",
    "        # Convert Label column from string to dictionary \n",
    "        cases_df[self.weighted_skin_condition_label] = cases_df[self.weighted_skin_condition_label].apply(lambda x: ast.literal_eval(x))\n",
    "        cases_df[self.skin_condition_label] = cases_df[self.skin_condition_label].apply(lambda x: ast.literal_eval(x))\n",
    "        df = cases_df[['case_id', 'image_1_path', 'image_2_path', 'image_3_path', 'dermatologist_skin_condition_on_label_name', 'weighted_skin_condition_label']]\n",
    "        \n",
    "        # Convert wide format to long format\n",
    "        df = pd.melt(df, id_vars=['case_id','dermatologist_skin_condition_on_label_name', 'weighted_skin_condition_label'], value_vars=['image_1_path', 'image_2_path', 'image_3_path'])\n",
    "        # Drop extra column\n",
    "        df.drop(['variable'], axis=1, inplace=True)\n",
    "        # Drop rows where there is no image\n",
    "        df = df[df['value'].notna()] \n",
    "        \n",
    "        #Only keep labels with atleast 50 occurrences\n",
    "        selected_label_counts = df[self.skin_condition_label].explode().dropna().value_counts()\n",
    "        selected_labels = set(selected_label_counts[selected_label_counts>=50].keys())\n",
    "        df[self.skin_condition_label] = df[self.skin_condition_label].apply(lambda x: list(set(x).intersection(selected_labels)))\n",
    "\n",
    "        \n",
    "        # Drop row where 1 image is not present\n",
    "        df = df[df['value']!= \"dataset/images/-2243186711511406658.png\"]\n",
    "        \n",
    "        # Drop rows where there is no label\n",
    "        self.df = df[df['dermatologist_skin_condition_on_label_name'].map(lambda d: len(d)) > 0].reset_index(drop=True) \n",
    "        self.df.rename(columns={\"dermatologist_skin_condition_on_label_name\": \"labels\", \n",
    "                                \"weighted_skin_condition_label\": \"weighted_labels\", \n",
    "                                \"value\": \"paths\"\n",
    "                               }, inplace=True)\n",
    "\n",
    "        # One Hot Encoding for Labels\n",
    "        one_hot = MultiLabelBinarizer()\n",
    "        self.encoded_labels = torch.from_numpy(one_hot.fit_transform(self.df[\"labels\"])).to(torch.float32)\n",
    "        self.all_labels = one_hot.classes_\n",
    "\n",
    "        # Calculate Weights to handle Class Imbalance [N/N_i*N_labels]\n",
    "        self.class_weights = self.df[\"labels\"].explode().value_counts().apply(lambda x: round(len(self.df)/( len(self.all_labels) * x ) , 10)).tolist()\n",
    "\n",
    "        # Set Transforms to increase diversity\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize( (224, 224) , interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.RandomInvert(p=0.4),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        self.paths = list(self.df[\"paths\"])\n",
    "        \n",
    "    def __len__(self):\n",
    "        '''\n",
    "        Return the length of dataset\n",
    "        '''\n",
    "        return len(self.encoded_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        Return a data sample\n",
    "        '''\n",
    "        path = self.paths[idx]\n",
    "        if isinstance(path, str):\n",
    "            # One file is missing from the dataset, so we handle that manually\n",
    "            if path == \"dataset/images/-2243186711511406658.png\": pass\n",
    "            image = Image.open(path)\n",
    "            # Convert to 3 channels in case needed\n",
    "            if len(np.array(image).shape) == 2:\n",
    "                copied_images = [np.array(image).copy() for _ in range(3)]\n",
    "                image = np.stack(copied_images, axis=-1)\n",
    "                image = Image.fromarray(image)\n",
    "\n",
    "            # Apply Transform as per ResNet Requirements\n",
    "            image = self.transform(image)\n",
    "        return path, (image, self.encoded_labels[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1a6f30-404a-4bb6-985a-b42fb9bd54a4",
   "metadata": {},
   "source": [
    "## Split the dataset into Train/Validation/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7940cdf1-afef-41d5-91b8-049c260c74df",
   "metadata": {},
   "outputs": [],
   "source": [
    "scin_dataset = SCINDataset()\n",
    "data_len = len(scin_dataset)\n",
    "print(\"Total number of images: \", data_len)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(scin_dataset,\n",
    "                                                        (data_len-1000, 500, 500), generator=torch.Generator().manual_seed(42))\n",
    "train_loader = DataLoader(dataset=train_dataset, shuffle=True, batch_size=64, drop_last=True, num_workers=8, pin_memory=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, shuffle=False, batch_size=64, num_workers=8, pin_memory=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, shuffle=False, batch_size=64, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c3b3b1-9069-41d3-8e44-e967ef291bff",
   "metadata": {},
   "source": [
    "## Training and Validation Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8632d9-0a6e-4439-b928-9688c1d4f2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(scin_dataset.all_labels)\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.0001\n",
    "THRESHOLD = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf136dbd-a41f-43b9-84b8-b6853883131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet50 model without the top layer\n",
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "# Change final output to number of classes\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, NUM_CLASSES),\n",
    ")\n",
    "\n",
    "# Move model to GPU if available\n",
    "model = model.to(device)\n",
    "\n",
    "# Apply Weighted BCE Loss (Sigmoid included for numeric stability)\n",
    "class_weights_tensor = torch.tensor(scin_dataset.class_weights, dtype=torch.float32).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights_tensor)\n",
    "\n",
    "# Define Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE, weight_decay = 1e-8)\n",
    "\n",
    "# Train and Validate\n",
    "print(f\"Training for {EPOCHS} Epochs\")\n",
    "train_losses, val_losses = [], []\n",
    "# Training Loop\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    i = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward + optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # train_losses.append(loss.item())\n",
    "        running_loss += loss.item()\n",
    "        i+=1\n",
    "        \n",
    "    train_loss = running_loss/len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Get validation loss and predictions on validation set\n",
    "    model.eval()\n",
    "    runninng_val_loss = 0.0\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels in val_loader:\n",
    "            val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
    "            val_outputs = model(val_inputs)\n",
    "            val_loss = criterion(val_outputs, val_labels).item()\n",
    "            runninng_val_loss += val_loss\n",
    "            y_true.append(val_labels.cpu().numpy())\n",
    "            y_pred.append(torch.sigmoid(val_outputs).cpu().numpy())\n",
    "    runninng_val_loss /= len(val_loader)\n",
    "    val_losses.append(runninng_val_loss)\n",
    "    \n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    \n",
    "    y_pred = (y_pred > THRESHOLD).astype(int)\n",
    "\n",
    "    # Get Performance metrics on validation set\n",
    "    macro_score = precision_recall_fscore_support(y_true, y_pred, average=\"macro\")\n",
    "    micro_score = precision_recall_fscore_support(y_true, y_pred, average=\"micro\")\n",
    "    weighted_score = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}], Training Loss: {train_loss}, Validation Loss: {runninng_val_loss:.4f}, \\n \\n Accuracy: {accuracy} \\n Macro Scores: {macro_score} \\n Micro Scores: {micro_score} \\n Weighted Scores: {weighted_score}\\n \")\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07ba51d-151b-4406-a9e5-74b86d80e121",
   "metadata": {},
   "source": [
    "## Visualize the Training and Validation Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c9d048-9402-4c3b-8a08-8649050dfc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce34e0d-0ba4-4b4f-8907-1816777e71fd",
   "metadata": {},
   "source": [
    "## Perform inference on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e215c50-b2d7-4ce2-b348-b2a130727f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for idx, (test_inputs, test_labels) in enumerate(test_loader):\n",
    "        print(idx)\n",
    "        test_inputs, test_labels = test_inputs.to(device), test_labels.to(device)\n",
    "        test_outputs = model(test_inputs)\n",
    "        y_true.append(test_labels.cpu().numpy())\n",
    "        y_pred.append(torch.sigmoid(test_outputs).cpu().numpy())\n",
    "            \n",
    "y_true = np.concatenate(y_true)\n",
    "y_pred = np.concatenate(y_pred)\n",
    "\n",
    "y_pred = (y_pred > THRESHOLD).astype(int)\n",
    "\n",
    "macro_score = precision_recall_fscore_support(y_true, y_pred, average=\"macro\")\n",
    "micro_score = precision_recall_fscore_support(y_true, y_pred, average=\"micro\")\n",
    "weighted_score = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "\n",
    "print(f\"Macro Scores: {macro_score} \\n Micro Scores: {micro_score} \\n Weighted Scores: {weighted_score}\\n \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d09879-bd62-4c53-b2bf-144af1a790cb",
   "metadata": {},
   "source": [
    "## Save the model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feca908-2b62-4016-adb4-85198e23d557",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.bin')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
